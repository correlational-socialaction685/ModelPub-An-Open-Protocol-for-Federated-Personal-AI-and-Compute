# ModelPub Roadmap — v0.3 Draft

---

## M1 — Core Protocol Definition
- Define message types: `model_update`, `compute_offer`, `compute_request`, `policy_notice`.
- Specify cryptographic signature format and verification flow.
- Define `Personal Vault` for data and model storage.
- Define `Compute Pool` for shared resource management.

## M2 — Reference Implementation (Local & Peer-to-Peer)
- Build minimal Python/CLI reference node.
- Implement signing, encryption, and compute exchange receipts.
- Introduce peer discovery and trust domains.
- Support both federated learning and compute-sharing flows.

## M3 — Community Federation Layer
- Add domain-based federation (trusted communities).
- Enable rate limits, load balancing, and opt-in compute donation.  
- Implement audit logs and local policy enforcement.  
- Support low-power devices through shared compute resources.

## M4 — Governance, Ethics, and Model Independence
- Formalize open working group and RFC submission model.  
- Define ethical compute principles and energy constraints.  
- Support model-agnostic participation (any architecture).  
- Draft interoperability test suite and compliance badge.

## M5 — User Interface Layer (Future Vision)
- Design concept for "Personal AI Access Gateway" (UI layer).  
- Enable cross-device access to user nodes.  
- Integrate compute federation backend for near-instant responses.  
- Prototype open-source client similar to ChatGPT, powered by ModelPub.

---

**Long-term vision:**  
ModelPub forms the basis of a **global cooperative intelligence network** —  
where data, models, and compute power are shared responsibly and transparently.
